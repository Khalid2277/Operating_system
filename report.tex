\documentclass[11pt,a4paper]{article}
\usepackage[margin=1in]{geometry}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{hyperref}
\usepackage{fancyhdr}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{booktabs}
\usepackage{enumitem}

% Code listing style
\lstset{
    basicstyle=\ttfamily\small,
    breaklines=true,
    frame=single,
    language=C,
    numbers=left,
    numberstyle=\tiny\color{gray},
    commentstyle=\color{green!50!black},
    keywordstyle=\color{blue},
    backgroundcolor=\color{gray!5}
}

% Header and footer
\pagestyle{fancy}
\fancyhf{}
\rhead{Producer-Consumer Application}
\lhead{Operating Systems Project}
\rfoot{Page \thepage}

\title{\textbf{Multithreaded Producer-Consumer Application\\with Priority Handling and Performance Metrics}}
\author{
    Khalid Alfahim - b00100122 \\
    Ahmad Mustafawi - b00094873\\
    \\
    \textit{Operating Systems - CMP 310} \\
    \textit{American University of Sharjah}
}
\date{November 16, 2025}

\begin{document}

\maketitle

\section{Design Decisions}

\subsection{Synchronization Strategy}

Our implementation uses semaphores and mutexes to ensure thread-safe access to the shared buffer and prevent race conditions.

\textbf{Semaphores for Buffer Management:} We use three semaphores for synchronization. The \texttt{mutex} semaphore (initialized to 1) provides mutual exclusion for critical sections. The \texttt{empty} semaphore (initialized to buffer size) tracks available slots and blocks producers when the buffer is full. The \texttt{full} semaphore (initialized to 0) tracks occupied slots and blocks consumers when the buffer is empty. This approach eliminates busy-waiting, as threads block efficiently on semaphore operations.

\textbf{Critical Section Protection:} The \texttt{mutex} semaphore protects the buffer during insertion and removal operations, ensuring only one thread modifies the buffer at a time. A separate \texttt{stats\_lock} mutex protects shared statistics counters to prevent race conditions during metric updates.

\textbf{Rationale:} This synchronization strategy prevents overflow/underflow conditions, data corruption, and race conditions without busy-waiting or inefficient polling mechanisms.

\subsection{Circular Buffer Implementation}

The buffer uses a dynamically allocated array with \texttt{in} and \texttt{out} indices that wrap around using modulo arithmetic: \texttt{(index + 1) \% buffer\_size}. The \texttt{in} index points to where the next item will be inserted (producer), and \texttt{out} points to where the next item will be removed (consumer).

\textbf{Rationale:} Circular buffers maximize memory efficiency by reusing array slots. The modulo operation handles wrapping automatically, enabling continuous operation without memory reallocation.

\subsection{Priority Handling (Bonus Feature)}

Each buffer item contains a priority field (0=normal, 1=urgent). When inserting an urgent item, we scan backward from the tail to identify normal priority items, shift them one position toward the tail, and insert the urgent item ahead of them. This maintains FIFO order within each priority level while ensuring urgent items are always processed first.

\textbf{Rationale:} This approach avoids the complexity of maintaining separate queues while guaranteeing priority ordering. The shifting operation, performed within the mutex-protected critical section, ensures atomicity. Approximately 25\% of items are marked urgent via random probability checking.

\subsection{Poison Pill Termination}

After all producer threads complete and are joined, the main thread inserts one poison pill (special value $-1$) per consumer into the buffer. Upon receiving a poison pill, each consumer terminates its loop gracefully. Poison pills are marked with urgent priority to ensure immediate processing.

\textbf{Rationale:} This technique guarantees that consumers don't exit prematurely while producers are still active, and ensures all real items are consumed before termination. It provides clean, deterministic shutdown without polling or timeout mechanisms.

\subsection{Performance Metrics (Bonus Feature)}

Each item records an enqueue timestamp using \texttt{gettimeofday()} when produced. Consumers record dequeue timestamps upon removal, calculating latency as the difference. Average latency and throughput (items/second) are computed and displayed after all threads complete.

\textbf{Rationale:} These metrics provide quantitative insight into system performance, demonstrating how buffer size affects contention, latency, and throughput. Microsecond-precision timestamps enable meaningful measurements even for fast operations.

\section{Challenges and Solutions}

\subsection{Challenge 1: Priority Queue in Circular Buffer}

\textbf{Problem:} Implementing priority handling in a circular buffer is challenging because standard circular buffers follow strict FIFO ordering. We needed to maintain FIFO within each priority level while allowing urgent items to bypass normal items.

\textbf{Solution:} We developed a shifting algorithm that scans backward from the insertion point to identify consecutive normal priority items at the tail. These items are shifted forward one position, creating space to insert the urgent item ahead of them. This preserves FIFO within priorities while allowing urgent items to "jump ahead."

\begin{lstlisting}[caption={Priority Insertion Logic}, captionpos=b]
// Count consecutive normal items at tail
int check_pos = (in - 1 + buffer_size) % buffer_size;
int shift_count = 0;

while (check_pos != out && 
       buffer[check_pos].priority == 0 && 
       shift_count < buffer_size) {
    shift_count++;
    check_pos = (check_pos - 1 + buffer_size) % buffer_size;
}

// Shift normal items forward and insert urgent item
\end{lstlisting}

\subsection{Challenge 2: Race Conditions in Statistics}

\textbf{Problem:} Multiple threads concurrently updating shared counters (\texttt{total\_produced}, \texttt{total\_consumed}, \texttt{total\_latency}) could cause race conditions and incorrect counts.

\textbf{Solution:} We introduced a separate \texttt{stats\_lock} mutex specifically for protecting statistics updates. This prevents contention with the main buffer semaphore and allows statistics updates to occur independently.

\subsection{Challenge 3: Thread-Safe Random Number Generation}

\textbf{Problem:} The standard \texttt{rand()} function uses shared state and is not thread-safe, potentially causing race conditions when called from multiple producer threads.

\textbf{Solution:} We use \texttt{rand\_r()} with per-thread seeds: \texttt{unsigned int seed = time(NULL) + producer\_id}. This allows each thread to maintain its own random state without shared state or locking overhead.

\subsection{Challenge 4: Memory Management}

\textbf{Problem:} Dynamic memory allocation for thread IDs, buffers, and latency arrays requires careful management to avoid memory leaks.

\textbf{Solution:} We allocate thread IDs in main, pass them to thread functions, and free them immediately after use inside each thread. Buffers and arrays are allocated during initialization and freed in a dedicated cleanup function called at program termination.

\subsection{Challenge 5: Poison Pill Timing}

\textbf{Problem:} Ensuring poison pills are inserted only after all real items have been produced, and that each consumer receives exactly one poison pill.

\textbf{Solution:} The main thread joins all producer threads before inserting poison pills, guaranteeing no more real items will be produced. We insert exactly \texttt{num\_consumers} poison pills, and consumers track them separately from real items.

\section{Performance Analysis}

We tested the application with varying buffer sizes to observe performance characteristics:

\begin{table}[h]
\centering
\caption{Performance Metrics for Different Buffer Sizes}
\begin{tabular}{@{}lccc@{}}
\toprule
\textbf{Configuration} & \textbf{Buffer Size} & \textbf{Avg Latency (sec)} & \textbf{Throughput (items/sec)} \\ \midrule
8P, 8C & 2 & $\sim$0.000065 & $\sim$20,000 \\
8P, 8C & 32 & $\sim$0.000020 & $\sim$50,000 \\ \bottomrule
\end{tabular}
\end{table}

\textbf{Interpretation:} Small buffers (2 slots) create high contention, causing frequent blocking and increased latency. Producers often wait for space, and consumers wait for data, reducing throughput. Larger buffers (32 slots) reduce contention significantly, allowing more concurrent operations. Producers can insert multiple items before blocking, and consumers have items readily available, resulting in 2.5× higher throughput and 3× lower latency. This demonstrates the critical impact of buffer sizing on concurrent system performance.

\section{Testing and Verification}

The application was rigorously tested with various configurations:
\begin{itemize}[leftmargin=*, itemsep=0pt]
    \item \textbf{Correctness:} Verified that total items produced equals total items consumed for all test cases
    \item \textbf{Priority Handling:} Confirmed through output logs that urgent items are consistently consumed before later-enqueued normal items
    \item \textbf{Concurrency:} Tested with up to 20 threads (10 producers, 10 consumers) without deadlocks or data corruption
    \item \textbf{Edge Cases:} Single thread (1P, 1C), minimal buffer (size 1), and large configurations all operate correctly
    \item \textbf{Memory Safety:} No memory leaks detected in validation testing
\end{itemize}

\section{Individual Contributions}

\begin{itemize}[leftmargin=*, itemsep=2pt]
    \item \textbf{[Khalid Alfahim]}: Implemented circular buffer structure and core semaphore/mutex synchronization mechanisms (30\%)
    \item \textbf{[Khalid Alfahim - Ahmad Mustafawi]}: Developed producer and consumer thread functions, implemented poison pill termination technique (30\%)
    \item \textbf{[Ahmad Mustafawi]}: Implemented priority handling bonus feature with shifting algorithm (20\%)
    \item \textbf{[Khalid Alfahim - Ahmad Mustafawi]}: Added performance metrics tracking, conducted testing, and wrote comprehensive documentation (20\%)
\end{itemize}

\section{Conclusion}

This project successfully demonstrates multithreaded programming with proper synchronization using POSIX semaphores and mutexes. The implementation correctly handles concurrent access to a shared circular buffer, provides graceful termination via the poison pill technique, and includes bonus features (priority handling and performance metrics) while maintaining code clarity and correctness.

Key achievements include:
\begin{itemize}[leftmargin=*, itemsep=0pt]
    \item Correct circular buffer implementation with \texttt{in}/\texttt{out} indexing
    \item Proper synchronization using semaphores (\texttt{mutex}, \texttt{empty}, \texttt{full})
    \item No busy-waiting, deadlocks, or race conditions
    \item Priority queue functionality maintaining FIFO within priority levels
    \item Comprehensive performance metrics (latency and throughput tracking)
    \item Robust error handling and memory management
\end{itemize}

The application meets all core requirements and successfully implements both bonus features, achieving 110\% of the base requirements.

\end{document}

